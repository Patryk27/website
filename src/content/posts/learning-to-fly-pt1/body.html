<p>
  In this series we'll create a simulation of <b>evolution</b> using <b>neural
  network</b> and <b>genetic algorithm</b>.
</p>

<p>
  I'm going to introduce you to how a basic neural network and genetic algorithm
  works, then we'll implement both in <b>Rust</b> and compile our application to
  <b>WebAssembly</b> to ultimately end up with:
</p>

<figure>
  <a href="https://shorelark.pwy.io">
    <img src="{{ assets }}/intro-outcome.png" />
  </a>

  <figcaption>
    <a href="https://shorelark.pwy.io" />
  </figcaption>
</figure>

<note>
  <p>
    This series is intended for <b>Rust beginners</b> - I'm assuming you know a
    thing or two about Rust and I'll introduce you to rest of the concepts (such
    as neural networks) as we go.
  </p>

  <p>
    No fancy mathematics or IT background is required.
  </p>
</note>

<p>
  This series will be divided into a few posts, roughly:
</p>

<ol>
  <li>
    <p>
      Introduction to the domain (what are we going to simulate, how does a
      neural network & genetic algorithm work),
    </p>
  </li>
  <li>
    <p>
      Implementing a neural network,
    </p>
  </li>
  <li>
    <p>
      Implementing a genetic algorithm,
    </p>
  </li>
  <li>
    <p>
      Implementing eyes, brain and the simulation itself.
    </p>
  </li>
</ol>

<p>
  Curious? Hop on the bus, Gus, and onto the first chapter:
  <a href="#design">Design</a>.
</p>

<toc />

<hdr id="design">
  Design
</hdr>

<p>
  Let's start by clearly defining our objective: what are we going to simulate,
  actually?
</p>

<p>
  The overall idea is that we have a two-dimensional board representing a
  <b>world</b>:
</p>

<figure class="sketch">
  <img src="{{ assets }}/design-1.svg" />
</figure>

<p>
  This world consists of <b>birds</b> (hence the project's original code name -
  <i>Shorelark</i>):
</p>

<figure class="sketch">
  <img src="{{ assets }}/design-2.svg" />
</figure>

<p>
  ... and <b>foods</b> (of an abstract kind, rich in protein & fiber):
</p>

<figure class="sketch">
  <img src="{{ assets }}/design-3.svg" />
</figure>

<p>
  Each bird has their own <b>vision</b>, allowing them to locate the food:
</p>

<figure class="sketch">
  <img src="{{ assets }}/design-4.svg" />
</figure>

<p>
  ... and a <b>brain</b> that controls bird's body (i.e. speed and rotation).
</p>

<p>
  Our magic touch will lay in the fact that instead of hard-coding our birds to
  some specific behavior (e.g. "go to the nearest food in your eyesight"), we'll
  take a more interesting route:
</p>

<p class="text-center">
  We'll make our birds able to <b>learn</b> and <b>evolve</b>.
</p>

<hdr id="brain">
  Brain
</hdr>

<p>
  If you squint your eyes hard enough, you'll see that a brain is nothing but a
  <b>function</b> of some inputs to some outputs, e.g.:
</p>

<figure class="sketch">
  <img src="{{ assets }}/brain-1.svg" />
</figure>

<note>
  <p>
    You're a precious mathematical formula, remember that.
  </p>
</note>

<p>
  Since our birds will have only one sensory input, their brains can be then
  approximated as:
</p>

<figure class="sketch">
  <img src="{{ assets }}/brain-2.svg" />
</figure>

<p>
  Mathematically, we can represent this function's input (i.e. biological
  <i>eye</i>) as a list of numbers, with each number (i.e. biological
  <i>photoreceptor</i>) describing how close the nearest object (i.e. food) is:
</p>

<figure class="sketch w-70">
  <img src="{{ assets }}/brain-3.svg" />
</figure>

<p class="text-center">
  <i>
    (<code>0.0</code> - no object in sight, <code>1.0</code> - object right in
    front of us.)
  </i>
</p>

<note>
  <p>
    Our birds won't see color, but that's just for simplicity - you could use
    e.g.
    <a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html">
      raytracing
    </a>
    to make the eyes more realistic.
  </p>
</note>

<p>
  As for the output, we'll make our function return a tuple of
  <code>(Δspeed, Δrotation)</code>.
</p>

<p>
  For instance, a brain telling us <code>(0.1, 45)</code> will mean "body,
  please increase our speed by <code>0.1</code> units and rotate us
  <code>45</code> degrees clockwise", while <code>(0.0, 0)</code> will mean
  "body, please keep our course steady".
</p>

<note>
  <p>
    It's important that we use relative values (so <code>delta speed</code> and
    <code>delta rotation</code>), as our brain won't be aware of its own
    location & rotation respective to the world - passing that information would
    increase our brain's complexity for no real benefit.
  </p>
</note>

<p>
  Finally, let's address the elephant in the room: so a brain is basically
  <code>f(eyes)</code>, right? But how do we find out what actually
  <i>follows</i> the equals sign?
</p>

<p class="text-center">
  <code>f(eyes) = what?</code>
</p>

<hdr id="nn-intro">
  Neural network: Introduction
</hdr>

<p>
  As a fellow human, you might be aware that brains are made of neurons
  connected via synapses:
</p>

<figure class="sketch w-50">
  <img src="{{ assets }}/nn-1.svg" />

  <figcaption>
    My attempt at drawing neurons - not to scale
  </figcaption>
</figure>

<p>
  Synapses carry electric and chemical signals between neurons, while neurons
  "decide" whether given signal should be propagated further or stopped;
  eventually this allows for people to recognize letters, eat brussels sprouts,
  and write mean comments on Twitter.
</p>

<p>
  <ref id="neuron">
    https://en.wikipedia.org/wiki/Biological_neuron_model
  </ref>

  <ref id="webscale">
    https://www.youtube.com/watch?v=b2F-DItXtZs
  </ref>

  Due to their <a ref="neuron">inherent complexity</a>, biological neural
  networks are not among the easiest to simulate (one could argue that neurons
  are thus not <a ref="webscale">Web Scale</a>), which made some smart people
  invent a class of mathematical structures called <b>artificial neural
  networks</b>, which allow to approximate - with a pinch of salt - brain-like
  behavior using math.
</p>

<p>
  <ref>
    https://en.wikipedia.org/wiki/Google_Neural_Machine_Translation
  </ref>

  Artificial neural networks (which I'm going to call just neural networks) are
  prominent at <b>generalizing</b> over datasets (e.g. learning how a cat looks
  like), so they found their use in face recognition (e.g. for cameras),
  language translation (e.g. for <a>GNMT</a>), and - in our case - to steer
  colorful pixels for a handful of Reddit karma.
</p>

<p>
  The particular kind of network we'll be focusing on is called
  <code>feedforward neural network</code> (FFNN)…​
</p>

<note>
  <p>
    <ref id="mlp">
      https://en.wikipedia.org/wiki/Multilayer_perceptron
    </ref>

    <ref id="cnn">
      https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53
    </ref>

    <ref id="dd">
      https://en.wikipedia.org/wiki/DeepDream
    </ref>

    Cool bear's hot tip: FFNNs are sometimes called <a ref="mlp">multilayer
    perceptrons</a> and they are one of the building blocks of
    <a ref="cnn">convolutional neural networks</a> such as
    <a ref="dd">DeepDream</a>.
  </p>
</note>

<p>
  ... and it looks like this:
</p>

<figure class="sketch">
  <img src="{{ assets }}/nn-2.svg" />

  <figcaption>
    Example of a multilayer perceptron (MLP), also called FFNN
  </figcaption>
</figure>

<p>
  This is a layout of an FFNN with <b>five synapses</b> and
  <b>three neurons</b>, all organized in <b>two layers</b>: the
  <b>input layer</b> (on the left side) and the <b>output layer</b> (on the
  right side).
</p>

<p>
  There may also exist layers in-between, in which case they are called
  <b>hidden layers</b> - they improve the network's ability to understand the
  input data (think: the bigger the brain, the "more abstraction" it might
  understand, to a certain degree).
</p>

<note>
  <p>
    A
    <a href="https://www.youtube.com/watch?v=rA5qnZUXcqo">similar process</a>
    happens inside your own
    <a href="https://en.wikipedia.org/wiki/Visual_cortex">visual cortex</a>,
    too.
  </p>
</note>

<p>
  Contrary to biological neural networks (which piggyback on electric signals),
  FFNNs work by accepting some <b>numbers</b> at their input and propagating
  (feedforwarding) those numbers layer-by-layer across the entire network;
  numbers that appear at the last layer determine network's answer.
</p>

<p>
  For instance, if you fed your network with raw pixels of a picture, you
  might've got a response saying:
</p>

<ul>
  <li>
    <p>
      <code>0.0</code> - this picture <i>does not</i> contain an orange cat
      eating lasagna,
    </p>
  </li>
  <li>
    <p>
      <code>0.5</code> - this picture <i>might</i> contain an orange cat eating
      lasagna,
    </p>
  </li>
  <li>
    <p>
      <code>1.0</code> - this picture <i>certainly</i> contains an orange cat
      eating lasagna.
    </p>
  </li>
</ul>

<p>
  It's also possible for a network to return many values (the number of output
  values is equal to the number of neurons in the output layer):
</p>

<ul>
  <li>
    <p>
      <code>(0.0, 0.5)</code> - this picture <i>does not</i> contain an orange
      cat, but <i>might</i> contain a lasagna,
    </p>
  </li>
  <li>
    <p>
      <code>(0.5, 0.0)</code> - this picture <i>might</i> contain an orange cat,
      but <i>does not</i> contain a lasagna.
    </p>
  </li>
</ul>

<p>
  The meaning of input and output numbers is up to you - in this case we've
  simply imagined that there exists <i>some</i> neural network behaving this
  way, but in reality it's on you to prepare so-called
  <b>training dataset</b> ("given this picture, you should return 1.0", "given
  that picture, you should return 0.0").
</p>

<note>
  <p>
    <ref>
      https://www.researchgate.net/publication/320662740_Identification_and_counting_of_mature_apple_fruit_based_on_BP_feed_forward_neural_network
    </ref>

    You might've as well created a network that, say, <a>identifies mature
    apples</a> - sky's the limit.
  </p>
</note>

<p>
  Having the general overview of FFNNs in mind, let's now take the next major
  step and learn about the magic allowing for all of this to happen.
</p>

<hdr id="nn-deep-dive">
  Neural network: Deep dive
</hdr>

<p>
  FFNNs lean on two building blocks: <b>neurons</b> and <b>synapses</b>.
</p>

<p>
  A <b>neuron</b> (usually represented with a circle) accepts some input values,
  processes them and returns some output value - each neuron has at least one
  input and at most one output:
</p>

<figure class="sketch">
  <img src="{{ assets }}/nn-3.svg" />

  <figcaption>
    A single neuron with three synapses
  </figcaption>
</figure>

<p>
  Additionally, each neuron has a <b>bias</b>:
</p>

<figure class="sketch">
  <img src="{{ assets }}/nn-4.svg" />

  <figcaption>
    A single neuron with three synapses and annotated bias value
  </figcaption>
</figure>

<p>
  Bias is like a neuron's <code>if</code> statement - it allows for a neuron to
  stay inactive (return an output of zero) unless> the input is strong (high)
  enough. Formally we'd say that bias allows to regulate neuron's <b>activation
  threshold</b>.
</p>

<p>
  Imagine you've got a neuron with three inputs, with each input determining
  whether it sees a lasagna (<code>1.0</code>) or not (<code>0.0</code>) - now,
  if you wanted to create a neuron that's activated when it sees <i>at least
  two</i> lasagnas, you'd simply create a neuron with a bias of
  <code>-1.0</code>; this way your neuron's "natural" state would be
  <code>-1.0</code> (inactive), with one lasagna - <code>0.0</code> (still
  inactive), and with two - <code>1.0</code> (active, voilà).
</p>

<note>
  <p>
    <ref>
      https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks
    </ref>

    If my lasagna metaphor doesn't appeal to you, you might find <a>this
    math-oriented explanation</a> more helpful.
  </p>
</note>

<p>
  Apart from neurons, we've got <b>synapses</b> - a synapse is like a wire that
  connects one neuron's output to another neuron's input; each synapse is of
  certain <b>weight</b>:
</p>

<figure class="sketch">
  <img src="{{ assets }}/nn-5.svg" />

  <figcaption>
    A single neuron with three synapses with annotated weights
  </figcaption>
</figure>

<p>
  A weight is a factor (hence the <code>x</code> before each number, to
  emphasize its multiplicative nature), so a weight of:
</p>

<ul>
  <li>
    <p>
      <code>0.0</code> means that a synapse is effectively dead (it doesn't pass
      any information from one neuron into the another),
    </p>
  </li>
  <li>
    <p>
      <code>0.3</code> means that if neuron A returns <code>0.7</code>, neuron B
      will receive <code>0.7 * 0.3 ~= 0.2</code>,
    </p>
  </li>
  <li>
    <p>
      <code>1.0</code> means that a synapse is effectively passthrough - if
      neuron A returns <code>0.7</code>, neuron B will receive
      <code>0.7 * 1.0 = 0.7</code>.
    </p>
  </li>
</ul>

<p>
  Having all this knowledge in mind, let's go back to our network and fill-in
  missing weights & biases with some random numbers:
</p>

<figure class="sketch w-70">
  <img src="{{ assets }}/nn-6.svg" />
</figure>

<p>
  What a beauty, isn't it?
</p>

<p>
  Let's see what it thinks of, say, <code>(0.5, 0.8)</code>:
</p>

<figure class="sketch w-70">
  <img src="{{ assets }}/nn-7.svg" />
</figure>

<p>
  To reiterate, we're interested in the output value of the rightmost neuron
  (that's our output layer) - since it depends on two previous neurons (the ones
  from the input layer), we're going to start with them.
</p>

<p>
  Let's focus on the top-left neuron first - to calculate its output, we start
  by computing a <b>weighted sum</b> of all its inputs:
</p>

<code lang="text">
  <!--
    0.5 * 0.2 = 0.1
  -->
</code>

<p>
  ... then, we add the bias:
</p>

<code lang="text">
  <!--
    0.1 - 0.3 = -0.2
  -->
</code>

<p>
  ... and <b>clamp</b> this value through so-called <b>activation function</b>;
  activation function limits neuron's output to a predefined range, simulating
  the <code>if</code>-like behavior.
</p>

<p>
  <ref>
    https://doc.rust-lang.org/stable/std/primitive.f32.html#method.max
  </ref>

  The simplest activation function is
  <b>rectified linear unit</b> (<code>ReLU</code>), which is basically
  <a><code>f32::max</code></a>:
</p>

<figure class="sketch w-50">
  <img src="{{ assets }}/nn-8.svg" />
</figure>

<note>
  <p>
    <ref>
      https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks
    </ref>

    Another popular activation function is <code>tanh</code> - its graph looks
    slightly different (like an <code>s</code>) and it's got <a>different
    properties</a>.
  </p>

  <p>
    Activation function affects network's input and output - e.g.
    <code>tanh</code> forces a network to work on numbers from range
    <code>&lt;-1.0, 1.0&gt;</code> instead of <code>&lt;0.0, +inf&gt;</code>, as
    compared to <code>ReLU</code>.
  </p>
</note>

<p>
  As you can see, when our weighted-sum-with-a-bias is lower than zero, the
  neuron's output will be <code>0.0</code> - and that's exactly what happens to
  our current output:
</p>

<code lang="text">
  <!--
    max(-0.2, 0.0) = 0.0
  -->
</code>

<p>
  Nice; now let's do the bottom-left one:
</p>

<code lang="text">
  <!--
    # Weighted sum:
    0.8 * 1.0 = 0.8
    
    # Bias:
    0.8 + 0.0 = 0.8
    
    # Activation function:
    max(0.8, 0.0) = 0.8
  -->
</code>

<p>
  At this point we've got the input layer completed:
</p>

<figure class="sketch w-70">
  <img src="{{ assets }}/nn-9.svg" />
</figure>

<p>
  ... which heads us towards the last neuron:
</p>

<code lang="text">
  <!--
    # Weighted sum:
    (0.0 * 0.6) + (0.8 * 0.5) = 0.4
    
    # Bias:
    0.4 + 0.2 = 0.6
    
    # Activation function:
    max(0.6, 0.0) = 0.6
  -->
</code>

<p>
  ... and the network's output itself:
</p>

<code lang="text">
  <!--
    0.6 * 1.0 = 0.6
  -->
</code>

<p>
  Voilà - for the input of <code>(0.5, 0.8)</code>, our network responded
  <code>0.6</code>.
</p>

<p>
  <i>
    (since it's just an exercise on a totally made-up network, this number
    doesn't mean anything - it's just some output value.)
  </i>
</p>

<p>
  <ref>
    https://medium.com/@jayeshbahire/the-xor-problem-in-neural-networks-50006411840b
  </ref>

  Overall, that's one of the simplest FFNNs possible - given appropriate
  weights, it's able to solve <a>the XOR problem</a>, but probably lacks the
  capacity to steer a bird.
</p>

<p>
  More complex FFNNs, such as this one:
</p>

<figure class="sketch w-70">
  <img src="{{ assets }}/nn-10.svg" />
</figure>

<p>
  ... work exactly the same way: you just go left-to-right, neuron-by-neuron,
  computing the outputs, until you squeeze all the numbers from the output
  layer.
</p>

<p>
  <i>
    (on that particular diagram some of the synapses overlap, but it doesn't
    mean anything: it's just that representing multidimensional graphs on a flat
    screen is unfortunate.)
  </i>
</p>

<p>
  At this point you might begin to wonder "wait, how do we <i>know</i> our
  network's weights?", and for that I've got a simple answer:
</p>

<p class="text-center">
  <b>we randomize them</b>! ❤️️
</p>

<p>
  If you're accustomed to deterministic algorithms (bubble sort, anyone?), this
  might feel itchy to you, but it's the way things go for networks containing
  more than a few neurons: you cross your fingers, randomize the initial weights
  and work with what you got.
</p>

<p>
  Notice I said <i>initial</i> weights - having some non-zero weights in place,
  there are certain algorithms that you can apply on your network to improve it
  (so, essentially, to teach it).
</p>

<p>
  One of the most popular "teaching" algorithms for FFNNs is
  <a href="https://www.youtube.com/watch?v=tIeHLnjs5U8">backpropagation</a>:
</p>

<p>
  You show your network lots (think: hundredths of thousands) of examples in the
  form of "for this input, you should return that" (think: "for this picture of
  <i>dakimakura</i>, you should return <i>pillow</i>") and backpropagation
  slowly adjusts your network's weights until it gets the answers right.
</p>

<note>
  <p>
    Or not - a network might get stuck at a
    <a href="https://en.wikipedia.org/wiki/Local_optimum">local optimum</a> and
    "just" stop learning.
  </p>

  <p>
    Also, if you ever find yourself doing a neural network crossword, remember
    that backpropagation is an example of
    <a href="https://en.wikipedia.org/wiki/Supervised_learning">
      supervised learning
    </a>.
  </p>
</note>

<p>
  Backpropagation is a great tool if you have a rich set of labeled examples
  (such as photos or statistics) and that's why it doesn't fit our original
  assumption:
</p>

<p>
  We ain't no statisticians, the world is a cruel place, so we want for our
  birds to figure out all the learning on their own (contrary to being given
  concrete examples of "for this vision, go left", "for this vision, go right").
</p>

<p>
  Solution?
</p>

<p class="text-center">
  <del>biology</del> genetic algorithms and the magic of
  <a href="https://en.wikipedia.org/wiki/Law_of_large_numbers">large numbers</a>
</p>

<hdr id="ga-intro">
  Genetic algorithm: Introduction
</hdr>

<p>
  <ref>
    https://en.wikipedia.org/wiki/Universal_approximation_theorem
  </ref>

  To recap, from the mathematical point of view our underlying problem is that
  we have a function (<a>represented</a> using a neural network) that's defined
  by a whole lot of <b>parameters</b>:
</p>

<figure class="sketch w-90">
  <img src="{{ assets }}/ga-1.svg" />
</figure>

<p>
  <i>
    (I didn't bother to draw all the weights, but I hope you get the point -
    there's a lot of them.)
  </i>
</p>

<p>
  Had we represented each parameter with a single-precision floating-point
  number, a network of mere 3 neurons and 5 synapses could be defined in so many
  different combinations…​
</p>

<code lang="text">
  <!--
    (3.402 * 10^38) ^ (3 + 5) ~= 1.8 * 10^308
  -->
</code>

<p class="text-attached">
  (<a href="https://jameshoward.us/2015/09/09/how-many-floating-point-numbers-are-there/">
  how-many-floating-point-numbers-are-there
  </a>)
</p>

<p>
  <ref>
    https://en.wikipedia.org/wiki/Heat_death_of_the_universe
  </ref>

  ... that the universe would sooner meet its <a>ultimate fate</a> than we'd be
  done checking them all - we certainly need to be smarter!
</p>

<note>
  <p>
    All the possible sets of parameters are called a <b>search space</b>.
  </p>
</note>

<p>
  Since iterating through our search space looking for the single best answer is
  off the table, we can focus on a much simpler task of finding a list of
  suboptimal answers.
</p>

<p class="text-center">
  And in order to do that, we must <b>dig deeper</b>.
</p>

<hdr id="ga-deep-dive">
  Genetic algorithm: Deep dive
</hdr>

<p>
  This is a wild carrot together with its domesticated form:
</p>

<figure class="sketch">
  <img src="{{ assets }}/carrot.jpg" />
</figure>

<p>
  <ref>
    https://en.wikipedia.org/wiki/Selective_breeding
  </ref>

  This domesticated, widely known form didn't appear out of blue - it's an
  outcome of hundredths of years of <a>selective breeding</a> with certain
  factors - like taproot's texture or color - in mind.
</p>

<p>
  Wouldn't it be awesome if we could do a similar thing with our neural brains?
  If we just, like, created a bunch of random birds and selectively bred the
  ones which seemed the most prominent…​
</p>

<p class="text-center">
  <b>hmmm</b>
</p>

<p>
  <ref>
    https://en.wikipedia.org/wiki/Evolutionary_computation
  </ref>

  As it turns out, we're not the first to stumble upon this idea - there already
  exists a widely researched branch of computer science called <a>evolutionary
  computation</a> that's all about solving problems "just the way nature would
  do".
</p>

<p>
  <ref>
    https://en.wikipedia.org/wiki/Genetic_algorithm
  </ref>

  Out of all the evolutionary algorithms, the concrete subclass we'll be
  studying is called <a>genetic algorithm</a>.
</p>

<note>
  <p>
    Similarly as with neural networks, there's no <i>the</i> genetic algorithm -
    it's a variety of different algorithms; so to avoid burning the midnight
    oil, we'll take a look at how things work in general.
  </p>
</note>

<p>
  Starting top-bottom, a genetic algorithm starts with a <b>population</b>:
</p>

<figure class="sketch">
  <img src="{{ assets }}/ga-2.svg" />
</figure>

<p>
  A population is built from <b>individuals</b> (sometimes called
  <b>agents</b>):
</p>

<figure class="sketch w-40">
  <img src="{{ assets }}/ga-3.svg" />
</figure>

<p>
  An <b>individual</b> (or an <b>agent</b>) is a single possible solution to
  given problem (a population is thus a set of possible solutions).
</p>

<p>
  In our case, each individual will model a brain (or an entire bird, if you
  prefer to visualise it this way), but generally it depends on the problem
  you're tackling:
</p>

<ul>
  <li>
    <p>
      <ref>
        https://en.wikipedia.org/wiki/Evolved_antenna
      </ref>

      If you were trying to, say, <a>evolve an antenna</a>, a single individual
      would be a single antenna.
    </p>
  </li>
  <li>
    <p>
      <ref>
        https://www.postgresql.org/docs/8.3/geqo-intro2.html
      </ref>

      If you were trying to, say, <a>evolve a query plan</a>, a single
      individual would be a single query plan.
    </p>
  </li>
</ul>

<note>
  <p>
    An individual represents some solution, but not necessarily the best one.
  </p>
</note>

<p>
  An individual is built from <b>genes</b> (collectively named <b>genome</b>):
</p>

<figure class="sketch w-40">
  <img src="{{ assets }}/ga-4.svg" />

  <figcaption>
    A genome represented with neural network’s weights; a genome might be a list
    of numbers, a graph or anything else that is able to model a solution to the
    problem
  </figcaption>
</figure>

<p>
  A <b>gene</b> is a single parameter that's being evaluated and tuned by the
  genetic algorithm.
</p>

<p>
  In our case, each gene will be simply a neural network's weight, but
  representing problem's domain isn't always this straightforward.
</p>

<p>
  <ref>
    https://en.wikipedia.org/wiki/Travelling_salesman_problem
  </ref>

  For instance, if you were trying to <a>help a fellow salesman</a>, where the
  underlying problem isn't based on neural networks at all, a single gene could
  be a tuple of <code>(x, y)</code> coordinates determining a part of the
  salesman's journey (consequently, an individual would then describe the
  salesman's entire path):
</p>

<figure class="sketch">
  <img src="{{ assets }}/ga-5.svg" />

  <figcaption>
    A hypothetical approach to the travelling salesman problem - each box
    represents a possible path for the salesman to travel
  </figcaption>
</figure>

<p>
  Now, let's say we've got a random population of fifty birds - we pass them to
  a genetic algorithm, what happens?
</p>

<p>
  Similarly as with selective breeding, genetic algorithm starts by
  <b>evaluating</b> each of the individuals (each of the possible solutions) to
  see which are the best among the current population.
</p>

<p>
  Biologically, this is an equivalent of taking a stroll to your garden and
  checking which carrots are the orangest and the yummiest.
</p>

<p>
  Evaluation happens using so-called <b>fitness function</b> that returns a
  <b>fitness score</b> quantifying how good a particular individual (so a
  particular solution) is:
</p>

<figure class="sketch">
  <img src="{{ assets }}/ga-6.svg" />

  <figcaption>
    An example of a fitness function that quantifies carrots by their taproot’s
    color and radius
  </figcaption>
</figure>

<p>
  Creating a
  <a href="https://www.youtube.com/watch?v=7J-DfS52bnI">usable</a> fitness
  function is one of the hardest tasks when it comes to genetic algorithms, as
  usually there are many metrics by which an individual can be measured.
</p>

<p>
  <i>
    (even our imaginative carrot has at least three metrics: taproot's color,
    radius and taste, and they all have to be squashed into a single number.)
  </i>
</p>

<p>
  Fortunately, when it comes to birds, we don't have much to choose from anyway:
  we'll just say that a bird is as good as the amount of food it ate during the
  course of the current generation.
</p>

<p>
  A bird who ate <code>30</code> foods is better than the one who ate just
  <code>20</code>, simple as that.
</p>

<note>
  <p>
    Negating a fitness function makes a genetic algorithm return the worst
    solutions instead of the best ones - just an amusing trick to remember for
    later.
  </p>
</note>

<p>
  Now, the time has come for the genetic algorithm's <i>crème de la crème</i>:
  <b>reproduction</b>!
</p>

<p>
  Broadly speaking, reproduction is the process of building a new (hopefully -
  slightly improved) population starting from the current one.
</p>

<p>
  It's the mathematical equivalent of choosing the tastiest carrots and planting
  their seeds.
</p>

<p>
  What happens is that the genetic algorithm chooses two individuals at random
  (prioritizing the ones with the higher fitness scores) and uses them to
  produce two <i>new</i> individuals (a so-called <b>offspring</b>):
</p>

<figure class="sketch">
  <img src="{{ assets }}/ga-7.svg" />
</figure>

<p>
  <ref id="cc">
    https://en.wikipedia.org/wiki/Chromosomal_crossover
  </ref>

  <ref id="mut">
    https://en.wikipedia.org/wiki/Mutation
  </ref>

  Offspring is produced by taking genomes of both parents and performing
  <a ref="cc"><b>crossover</b></a> and <a ref="mut"><b>mutation</b></a> on them:
</p>

<figure class="sketch w-70">
  <img src="{{ assets }}/ga-8.svg" />
</figure>

<note>
  <p>
    <b>Crossover</b> allows to mix two different gnomes to get an approximate
    in-between solution, while <b>mutation</b> allows to discover new solutions
    that weren't present in the initial population.
  </p>
</note>

<p>
  Both newly-spawned individuals are pushed into the pool of
  <code>new population</code> and the process starts over until the entire new
  population is built; the current population then gets discarded and the whole
  simulation starts over on this new (hopefully improved!) population.
</p>

<p>
  As you can see, there's a lot of <b>randomness</b> in the process: we start
  with a random population, we randomize how the genes are being distributed…​
  so…​
</p>

<p class="text-center">
  this cannot <i>actually</i> work, can it?
</p>
