<p>
  This is the second part of the <b>Learning to Fly</b> series in which we're
  coding a simulation of evolution using <b>neural network</b> and <b>genetic
  algorithm</b>:
</p>

<figure>
  <a href="https://shorelark.pwy.io">
    <img src="/posts/learning-to-fly-pt1/assets/intro-outcome.png" />
  </a>

  <figcaption>
    <a href="https://shorelark.pwy.io" />
  </figcaption>
</figure>

<p>
  In this post we'll lay the foundations for our project and implement a basic
  feed-forward neural network that'll later become a brain; we'll also take a
  look at many intricacies and idioms you might find in common Rust code,
  including in tests.
</p>

<p>
  Strap your straps, seatbelt your seatbelts and get ready for some coding!
</p>

<h2 id="setup">
  Setup
</h2>

<p>
  Oh, the joys of starting a new project!
</p>

<listing lang="shell">
  <!--
    $ mkdir shorelark
    $ cd shorelark

    # If you're using Git, it's also the time for:
    $ git init
  -->
</listing>

<p>
  First things first, we have to establish which toolchain version we'll be
  using - otherwise, if you happened to have an older toolchain installed, some
  parts of the code could not work for you.
</p>

<p>
  As of March 2024, the latest stable version of Rust is 1.76, so let's go ahead
  and create a file called <code>rust-toolchain</code> that says:
</p>

<listing-title>
  rust-toolchain
</listing-title>

<listing>
  <!--
  = 1.76.0
  -->
</listing>

<p>
  Phew!
</p>

<p>
  <ref id>
    https://doc.rust-lang.org/book/ch14-03-cargo-workspaces.html
  </ref>

  Now, for the more difficult part - we have to decide how our project's
  structure will look like. Because our project will consist of many independent
  submodules (such as the neural network and genetic algorithm), a
  <a ref>workspace</a> will come handy:
</p>

<listing-title>
  Cargo.toml
</listing-title>

<listing lang="toml">
  <!--
  = [workspace]
  = resolver = "2"
  =
  = members = [
  =     "libs/*",
  = ]
  -->
</listing>

<p>
  What this means is that instead of having <code>src/main.rs</code> right away,
  we'll create a directory called <code>libs</code> and put our hand-written
  libraries (aka <i>crates</i>) in there:
</p>

<listing lang="shell">
  <!--
  $ mkdir libs
  $ cd libs
  $ cargo new neural-network --name lib-neural-network --lib
  -->
</listing>

<note>
  <p>
    There are many approaches for organizing workspaces - instead of keeping
    everything in a directory called <code>libs</code>, you could dump
    everything into a directory called <code>crates</code> -- or you could
    create two separate directories, one for application-crates and another one
    for library-crates:
  </p>

  <listing lang="text">
    <!--
      project
      ├─ Cargo.toml
      ├─ app
      │  ├─ Cargo.toml
      │  └─ src
      │      └─ main.rs
      └─ libs
         ├─ subcrate-a
         │  ├─ Cargo.toml
         │  └─ src
         │     └─ lib.rs
         └─ subcrate-b
            ├─ Cargo.toml
            └─ src
               └─ lib.rs
    -->
  </listing>

  <p>
    There's no standard guideline, follow your gut (unless you're following this
    tutorial, in which case - follow this tutorial).
  </p>
</note>

<h2 id="coding-propagate">
  Coding: <code>propagate()</code>
</h2>

<p>
  It's time to get down to business.
</p>

<p>
  We'll start <b>top-down</b>, with a structure modelling the entire network -
  it will provide an <b>entry point</b> to our crate; let's open
  <code>lib.rs</code> and write:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
  = #[derive(Debug)]
  = pub struct Network;
  -->
</listing>

<p>
  A neural network's most crucial operation is propagating numbers:
</p>

<figure class="sketch w-70">
  <img src="{{ assets }}/coding-propagate-1.svg" />
</figure>

<p>
  ... so:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[derive(Debug)]
    pub struct Network;

  = impl Network {
  =     pub fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
  =         todo!()
  =     }
  = }
  -->
</listing>

<note>
  <p>
    While some languages allow to leave "work-in-progress" functions empty:
  </p>

  <listing lang="cpp">
    <!--
      int get_berry_number() {
          // TODO solve the paradox
      }
    -->
  </listing>

  <p>
    ... an equivalent code in Rust does not compile:
  </p>

  <listing lang="rust">
    <!--
      fn berry_number() -> usize {
          // TODO solve the paradox
      }
    -->
  </listing>

  <listing lang="text">
    <!--
      error[E0308]: mismatched types
       -\-> src/lib.rs
        |
      1 | fn berry_number() -> usize {
        |    ------------      ^^^^^ expected `usize`, found `()`
        |    |
        |    implicitly returns `()` as its body has no tail or `return`
        |    expression
    -->
  </listing>

  <p>
    That's because almost everything in Rust is an expression:
  </p>

  <listing lang="rust">
    <!--
      let value = if condition {
          "computer says yass"
      } else {
          "computer says no"
      };
      
      let value = loop {
          break 123;
      };
      
      let value = {
          // empty block is an expression, too
      };
    -->
  </listing>

  <p>
    ... and so the way Rust sees that function is actually:
  </p>

  <listing lang="rust">
    <!--
      fn berry_number() -> usize {
          return ();
      }
    -->
  </listing>

  <p>
    <ref>
      https://doc.rust-lang.org/std/primitive.unit.html
    </ref>

    ... with <code>()</code> being called <a ref>unit value</a> (or <b>unit
    type</b>, depending on context).
  </p>

  <p>
    To answer the problem of <i>but i really don't know how this function should
    look like just yet</i>, Rust provides two macros: <code>todo!()</code> and
    its older cousin - <code>unimplemented!()</code>.
  </p>

  <p>
    Both macros allow for the code to be compiled and, when encountered during
    runtime, cause the application to safely crash:
  </p>

  <listing lang="text">
    <!--
      thread 'main' panicked at 'not yet implemented'
    -->
  </listing>
</note>

<p>
  Similarly to an ocean filled with droplets, a network is built from layers:
</p>

<figure class="sketch w-70">
  <img src="{{ assets }}/coding-propagate-2.svg" />
</figure>

<p>
  ... so:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
  = #[derive(Debug)]
  = pub struct Network {
  =     layers: Vec<Layer>,
  = }
  =
  = #[derive(Debug)]
  = struct Layer;
  -->
</listing>

<p>
  Layers are built from neurons:
</p>

<figure class="sketch">
  <img src="{{ assets }}/coding-propagate-3.svg" />
</figure>

<p>
  ... giving us:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[derive(Debug)]
  = struct Layer {
  =     neurons: Vec<Neuron>,
  = }
  -->
</listing>

<p>
  Eventually, neurons contain biases and <b>output</b> weights:
</p>

<figure class="sketch w-50">
  <img src="{{ assets }}/coding-propagate-4.svg" />
</figure>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
  = #[derive(Debug)]
  = struct Neuron {
  =     bias: f32,
  =     weights: Vec<f32>,
  = }
  -->
</listing>

<p>
  Let's see our initial design in its entriety:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[derive(Debug)]
    pub struct Network {
        layers: Vec<Layer>,
    }
    
    impl Network {
        pub fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
            todo!()
        }
    }

    #[derive(Debug)]
    struct Layer {
        neurons: Vec<Neuron>,
    }

    #[derive(Debug)]
    struct Neuron {
        bias: f32,
        weights: Vec<f32>,
    }
  -->
</listing>

<p>
  Nice.
</p>

<note>
  <p>
    If you're perceptive or lucky, you might've noticed that only two of our
    objects are public: <code>Network</code> and
    <code>Network::propagate()</code>.
  </p>

  <p>
    That's because <code>Layer</code> and <code>Neuron</code> will remain an
    <b>implementation detail</b>, we won't expose them outside (that is, we
    won't make them public).
  </p>

  <p>
    Thanks to this approach, we'll be able to introduce changes to our
    implementation without imposing breaking changes on the <b>downstream</b>
    crates (the users of our library).
  </p>

  <p>
    <ref>
      https://towardsdatascience.com/diy-ai-an-old-school-matrix-nn-401a00021a55
    </ref>

    For instance, Real Neural Networks™ are usually implemented using
    <a ref>matrices</a> - if we ever decided to rewrite our network to use
    matrices as well, then it wouldn't be a breaking change:
    <code>Network::propagate()</code>'s signature would remain the same and
    since users can't access <code>Layer</code> and <code>Neuron</code>, they
    wouldn't be able to notice these two being gone.
  </p>
</note>

<p>
  Next, since numbers have to be shoved through each layer, we'll need to have a
  <code>propagate()</code> in there, too:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
  = impl Layer {
  =     fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
  =         todo!()
  =     }
  = }
  -->
</listing>

<p>
  Having <code>Layer::propagate()</code>, we can go back and implement
  <code>Network::propagate()</code>:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
        pub fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
  =         let mut inputs = inputs;
  =
  =         for layer in &self.layers {
  =             inputs = layer.propagate(inputs);
  =         }
  =
  =         inputs
        }
    }
  -->
</listing>

<p>
  This is quite a satisfying, correct piece of code - but it's also
  <b>non-idiomatic</b> - we can write it better, more <b>rustic</b>; let's see
  how!
</p>

<figure class="sketch">
  <img src="{{ assets }}/coding-propagate-5.svg" />

  <figcaption>
    Ecstasy of Saint Ferris (upon seeing idiomatic code), colorized
  </figcaption>
</figure>

<p>
  First of all, this is called a <b>rebinding</b> (or <i>shadowing</i>):
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
  = let mut inputs = inputs;
  -->
</listing>

<p>
  ... and it's unnecessary, because we might as well move this
  <code>mut</code> into the function's parameter:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
  =     pub fn propagate(&self, mut inputs: Vec<f32>) -> Vec<f32> {
            for layer in &self.layers {
                inputs = layer.propagate(inputs);
            }

            inputs
        }
    }
  -->
</listing>

<note>
  <p>
    But hey, won't this force our callers to pass mutable values? Nope!
  </p>

  <listing-title>
    <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=945c2c2852ccbeb143ea569747038626">
      open in playground
    </a>
  </listing-title>

  <listing lang="rust">
    <!--
      fn process(mut items: Vec<f32>) {
          // do something
      }
      
      fn main() {
          let items = vec![1.2, 3.4, 5.6];
          // ^ no `mut` needed here
      
          process(items);
          //      ^ just works
      }
    -->
  </listing>

  <p>
    The reasoning is that the <code>mut</code> we've just introduced appears in
    so-called <b>binding</b> position:
  </p>

  <listing lang="rust">
    <!--
      fn foo_1(items: &[f32]) {
          //   ^^^^^  ------
          //  binding  type
          // (immut.) (immut.)
      }
      
      fn foo_2(mut items: &[f32]) {
          //   ^^^^^^^^^  ------
          //    binding    type
          //   (mutable) (immut.)
      }
      
      fn foo_3(items: &mut [f32]) {
          //   ^^^^^  ----------
          //  binding    type
          // (immut.)  (mutable)
      }
      
      fn foo_4(mut items: &mut [f32]) {
          //   ^^^^^^^^^  ----------
          //    binding      type
          //   (mutable)   (mutable)
      }
      
      struct Person {
          name: String,
          eyeball_radius: usize,
      }
      
      fn decompose(Person { name, mut eyeball_radius }: Person) {
          //       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  ------
          //                     binding                 type
          // (partially immutable, partially mutable) (immutable)
      }
    -->
  </listing>

  <p>
    ... and bindings, contrary to types, are <b>local</b> to the function:
  </p>

  <listing lang="rust">
    <!--
      fn foo(items: &mut Vec<usize>) {
          // When a type is mutable, you can modify the thing being
          // referenced:
          items.push(1234);
      
          // But if the binding remains immutable, you cannot modify
          // *which* thing is referenced:
          items = some_another_vector;
          //    ^ error: cannot assign to immutable argument
      }
      
      fn bar(mut items: &Vec<usize>) {
          // On the other hand, when a binding is mutable, you can change
          // *which* thing is referenced:
          items = some_another_vector;
      
          // But if the type remains immutable, you cannot modify the
          // thing itself:
          items.push(1234);
          //   ^^^^^ error: cannot borrow `*items` as mutable, as it is
          //         behind a `&` reference
      }
    -->
  </listing>
</note>

<p>
  There's one more refinement we can apply to our code - this very pattern is
  known as <b>folding</b>:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    for layer in &self.layers {
        inputs = layer.propagate(inputs);
    }
  -->
</listing>

<p>
  ... and Rust's standard library provides a dedicated function for it:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
  =     pub fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
  =         self.layers
  =             .iter()
  =             .fold(inputs, |inputs, layer| layer.propagate(inputs))
        }
    }
  -->
</listing>

<p class="text-attached">
  (one could argue whether our final code is actually more readable or less -
  while I'm fond of the built-in combinators such as <code>.fold()</code>, if
  you find them obscure - that's fine, you do you!)
</p>

<p>
  Voilà - after all, thanks to the closure, we didn't even need that
  <code>mut inputs</code> - now you can brag about your code being all
  functional and Haskell-y.
</p>

<p>
  Let's move on to neurons - a single neuron accepts many inputs and returns a
  single output, so:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[derive(Debug)]
    struct Neuron {
        bias: f32,
        weights: Vec<f32>,
    }
    
  = impl Neuron {
  =     fn propagate(&self, inputs: Vec<f32>) -> f32 {
  =         todo!()
  =     }
  = }
  -->
</listing>

<p>
  As before, we can backtrack to implement <code>Layer::propagate()</code>:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[derive(Debug)]
    struct Layer {
        neurons: Vec<Neuron>,
    }
    
    impl Layer {
        fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
  =         let mut outputs = Vec::new();
  =
  =         for neuron in &self.neurons {
  =             let output = neuron.propagate(inputs);
  =             outputs.push(output);
  =         }
  =
  =         outputs
        }
    }
  -->
</listing>

<p>
  If we try to compile it, we get our first borrow-checker failure:
</p>

<listing lang="text">
  <!--
    error[E0382]: use of moved value: `inputs`
      -\-> src/lib.rs
       |
       |     fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
       |                         ------ move occurs because `inputs` has
       |                                type `Vec<f32>`, which does not
       |                                implement the `Copy` trait
      ...
       |             let output = neuron.propagate(inputs);
       |                                           ^^^^^^
       |                                value moved here, in previous
       |                                iteration of loop
  -->
</listing>

<p>
  Obviously, the compiler is right: after invoking
  <code>neuron.propagate(inputs)</code>, we lose ownership of
  <code>inputs</code>, so we can't use it in the loop's consecutive iterations.
</p>

<p>
  Fortunately, the fix is easy and boils down to making
  <code>Neuron::propagate()</code> work on <b>borrowed</b> values:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Layer {
        fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
            /* ... */
    
            for neuron in &self.neurons {
  =             let output = neuron.propagate(&inputs);
                /* ... */
            }
    
            /* ... */
        }
    }

    /* ... */
    
    impl Neuron {
  =     fn propagate(&self, inputs: &[f32]) -> f32 {
            /* ... */
        }
    }
  -->
</listing>

<p>
  To reiterate, the code we have at the moment is:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Layer {
        fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
            let mut outputs = Vec::new();
    
            for neuron in &self.neurons {
                let output = neuron.propagate(&inputs);
                outputs.push(output);
            }
    
            outputs
        }
    }
  -->
</listing>

<p>
  ... and, would you believe it, this particular pattern is called
  <b>mapping</b> and the standard library also provides a method for it!
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Layer {
        fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
  =         self.neurons
  =             .iter()
  =             .map(|neuron| neuron.propagate(&inputs))
  =             .collect()
        }
    }
  -->
</listing>

<p>
  Currently we've got nowhere else to go, but to complete
  <code>Neuron::propagate()</code> - as before, let's start with a crude,
  <a href="https://en.wikipedia.org/wiki/Superfund">superfund</a>-ish version:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
        fn propagate(&self, inputs: &[f32]) -> f32 {
  =         let mut output = 0.0;
  =
  =         for i in 0..inputs.len() {
  =             output += inputs[i] * self.weights[i];
  =         }
  =
  =         output += self.bias;
  =
  =         if output > 0.0 {
  =             output
  =         } else {
  =             0.0
  =         }
        }
    }
  -->
</listing>

<p>
  This snippet contains two unidiomatic constructs and one potential bug - let's
  start with the latter.
</p>

<p>
  Since we're iterating through <code>self.weights</code> using length from
  <code>inputs</code>, we've got three edge cases:
</p>

<ol>
  <li>
    <p>
      When <code>inputs.len() &lt; self.weights.len()</code>,
    </p>
  </li>
  <li>
    <p>
      When <code>inputs.len() == self.weights.len()</code>,
    </p>
  </li>
  <li>
    <p>
      When <code>inputs.len() &gt; self.weights.len()</code>.
    </p>
  </li>
</ol>

<p>
  Our code lays on the assumption that #2 is always true, but it's a
  <b>silent</b> assumption: we don't enforce it anywhere! If we mistakenly
  passed less or more inputs, we'd get either an invalid result or a crash.
</p>

<p>
  There are at least two ways we could go around improving it:
</p>

<ol>
  <li>
    <p>
      We could change <code>Neuron::propagate()</code> to return an error
      message:
    </p>

    <listing lang="rust">
      <!--
        impl Neuron {
            fn propagate(&self, inputs: &[f32]) -> Result<f32, String> {
                if inputs.len() != self.weights.len() {
                    return Err(format!(
                        "got {} inputs, but {} inputs were expected",
                        inputs.len(),
                        self.weights.len(),
                    ));
                }

                /* ... */
            }
        }
      -->
    </listing>

    <p>
      ... or, using one of the crates I love the most -
      <a href="https://github.com/dtolnay/thiserror">thiserror</a>:
    </p>

    <listing lang="rust">
      <!--
        pub type Result<T> = std::result::Result<T, Error>;
        
        #[derive(Debug, Error)]
        pub enum Error {
            #[error("got {got} inputs, but {expected} inputs were expected")]
            MismatchedInputSize {
                got: usize,
                expected: usize,
            },
        }
        
        /* ... */

        impl Neuron {
            fn propagate(&self, inputs: &[f32]) -> Result<f32> {
                if inputs.len() != self.weights.len() {
                    return Err(Error::MismatchedInputSize {
                        got: inputs.len(),
                        expected: self.weights.len(),
                    });
                }

                /* ... */
            }
        }
      -->
    </listing>
  </li>

  <li>
    <p>
      We could use <code>assert_eq!()</code> / <code>panic!()</code>:
    </p>

    <listing lang="rust">
      <!--
        impl Neuron {
            fn propagate(&self, inputs: &[f32]) -> f32 {
                assert_eq!(inputs.len(), self.weights.len());

                /* ... */
            }
        }
      -->
    </listing>
  </li>
</ol>

<p>
  In most cases, the first variant is better, because it allows for the caller
  to <b>catch</b> the error and <b>handle</b> it easily - in our case though,
  the error reporting is simply not worth it, because:
</p>

<ol>
  <li>
    <p>
      If this assertion ever fails, it means that our implementation is most
      likely wrong and there's nothing users could do <i>on their side</i> to
      mitigate the issue.
    </p>
  </li>
  <li>
    <p>
      This is a toy project, we've already got like fifty other ideas hanging in
      the air tonight, no need to waste our time.
    </p>
  </li>
</ol>

<p>
  So:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
        fn propagate(&self, inputs: &[f32]) -> f32 {
  =         assert_eq!(inputs.len(), self.weights.len());

            /* ... */
        }
    }
  -->
</listing>

<p>
  As for the idioms - this one:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
        fn propagate(&self, inputs: &[f32]) -> f32 {
            /* ... */

            if output > 0.0 {
                output
            } else {
                0.0
            }
        }
    }
  -->
</listing>

<p>
  ... is <code>f32::max()</code> in disguise:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
        fn propagate(&self, inputs: &[f32]) -> f32 {
            /* ... */

  =         output.max(0.0)
        }
    }
  -->
</listing>

<p>
  While this one:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
        fn propagate(&self, inputs: &[f32]) -> f32 {
            /* ... */

            let mut output = 0.0;

            for i in 0..inputs.len() {
                output += inputs[i] * self.weights[i];
            }

            /* ... */
        }
    }
  -->
</listing>

<p>
  ... can be simplified first with <code>.zip()</code>:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
        fn propagate(&self, inputs: &[f32]) -> f32 {
            /* ... */

            let mut output = 0.0;

  =         for (&input, &weight) in inputs.iter().zip(&self.weights) {
  =             output += input * weight;
  =         }

            /* ... */
        }
    }
  -->
</listing>

<note>
  <p>
    Array-indexing operations such as <code>inputs[i]</code> always perform a
    so-called <b>bounds check</b> - it's a piece of code which ensures that
    index lays within the array bounds, panicking when it's too big:
  </p>

  <listing lang="rust">
    <!--
      fn main() {
          let numbers = vec![1];
          println!("{}", numbers[123]);
      }
    -->
  </listing>

  <listing lang="text">
    <!--
      thread 'main' panicked at 'index out of bounds: the len is 1 but
      the index is 123'
    -->
  </listing>

  <p>
    When instead of indexing, you use combinators such as <code>.zip()</code> or
    <code>.map()</code>, you make it easier for the compiler to elide those
    checks, making your code not only more readable¹, but also faster.
  </p>

  <p>
    ¹ arguably, ofc.
  </p>
</note>

<p>
  ... and then using <code>.map()</code> + <code>.sum()</code>:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
        fn propagate(&self, inputs: &[f32]) -> f32 {
            /* ... */

  =         let mut output = input
  =             .iter()
  =             .zip(&self.weights)
  =             .map(|(input, weight)| input * weight)
  =             .sum::<f32>();

            /* ... */
        }
    }
  -->
</listing>

<note>
  <p>
    <ref>
      https://techblog.tonsser.com/posts/what-is-rusts-turbofish
    </ref>

    The <code>::&lt;&gt;</code> syntax used in the last line is called
    <a ref>turbofish</a> - it allows to provide explicit generic arguments when
    the compiler has troubles inferring them.
  </p>
</note>

<p>
  Voilà:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
        fn propagate(&self, inputs: &[f32]) -> f32 {
            assert_eq!(inputs.len(), self.weights.len());

  =         let output = inputs
  =             .iter()
  =             .zip(&self.weights)
  =             .map(|(input, weight)| input * weight)
  =             .sum::<f32>();
  =
  =         (self.bias + output).max(0.0)
        }
    }
  -->
</listing>

<p>
  It's unquestionably beautiful - but <b>does it work</b>? Can it recognize a
  cat? Can we use it to predict future Dogecoin prices?
</p>

<h2 id="coding-new">
  Coding: <code>new()</code>
</h2>

<p>
  Up to this point we were focused so much on the algorithm that we gave little
  to no thought to <b>contructors</b> - but how could we ever play with a
  network we cannot create?
</p>

<p>
  Our first approach for creating a constructor could be a plain,
  <abbr title="no-operation, i.e. doing nothing">no-op</abbr> function of:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[derive(Debug)]
    pub struct Network {
        layers: Vec<Layer>,
    }
    
    impl Network {
        pub fn new(layers: Vec<Layer>) -> Self {
            Self { layers }
        }

        /* ... */
    }
  -->
</listing>

<p>
  ... but it won't do in this case, because - as we've already established -
  we'd like to keep <code>Layer</code> and <code>Neuron</code> outside the
  public interface.
</p>

<p>
  If you recall our previous post, you might remember that we were talking a lot
  about random numbers - so if there's one thing I'm certain, it's that we'll
  need something in the lines of:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
        pub fn random() -> Self {
            todo!()
        }
    }
  -->
</listing>

<p>
  In order to randomize a network, we'll need to know the number of its layers
  and number of neurons per each layer - they all can be described with a single
  vector:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
        pub fn random(neurons_per_layer: Vec<usize>) -> Self {
            todo!()
        }
    }
  -->
</listing>

<p>
  ... or, in a bit more elegant way:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
  = #[derive(Debug)]
  = pub struct LayerTopology {
  =     pub neurons: usize,
  = }

    impl Network {
  =     pub fn random(layers: Vec<LayerTopology>) -> Self {
  =         todo!()
  =     }

        /* ... */
    }
    
    // By the way, notice how creating a separate type allowed us to untangle
    // argument's name to just `layers`.
    //
    // Initially we went with `neurons_per_layer`, because `Vec<usize>` doesn't
    // provide enough information to tell what this `usize` represents - using a
    // separate type makes the intention explicit.
  -->
</listing>

<p>
  Now, if you look real close at a neural network's layer:
</p>

<figure class="sketch w-30">
  <img src="{{ assets }}/coding-new-1.svg" />
</figure>

<p>
  ... perhaps you'll notice that it's actually defined by <b>two</b> numbers:
  its input and output size - does it mean our single-field
  <code>LayerTopology</code> is wrong? Au contraire!
</p>

<p>
  What we've done is, as I like to call it, <b>exploiting domain knowledge</b>.
</p>

<p>
  Inside a FFNN, all layers are connected consecutively, front-to-back:
</p>

<figure class="sketch">
  <img src="{{ assets }}/coding-new-2.svg" />
</figure>

<p>
  ... because layer A's output is layer B's input, if we went with:
</p>

<listing lang="rust">
  <!--
    #[derive(Debug)]
    pub struct LayerTopology {
        pub input_neurons: usize,
        pub output_neurons: usize,
    }
  -->
</listing>

<p>
  ... then not only would we make our interface unwieldy, but - what's more
  gruesome - we'd have to implement an additional validation ensuring that
  <code>layer[0].output_neurons == layer[1].input_neurons</code> etc. are met -
  pure nonsense!
</p>

<p>
  Noting this simple fact that consecutive layers must have matching inputs &
  outputs allows us to simplify the code before it's been even written.
</p>

<p>
  As for the implementation, a crude approach would be:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
        pub fn random(layers: Vec<LayerTopology>) -> Self {
  =         let mut built_layers = Vec::new();
  =
  =         for i in 0..(layers.len() - 1) {
  =             let input_size = layers[i].neurons;
  =             let output_size = layers[i + 1].neurons;
  =
  =             built_layers.push(Layer::random(
  =                 input_size,
  =                 output_size,
  =             ));
  =         }
  =
  =         Self { layers: built_layers }
        }
    }
  -->
</listing>

<p>
  ... and now let's rustify it -- care to guess what happens when you call
  <code>Network::random(vec![])</code>?
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
        pub fn random(layers: Vec<LayerTopology>) -> Self {
  =         // Network with just one layer is technically doable, but doesn't
  =         // make much sense:
  =         assert!(layers.len() > 1);

            /* ... */
        }
    }
  -->
</listing>

<p>
  There, better.
</p>

<p>
  As for the <code>for</code> loop - iterating by <b>adjacent</b> items is
  another pattern covered by the standard library, via a function called
  <code>.windows()</code>:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
        pub fn random(layers: Vec<LayerTopology>) -> Self {
            /* ... */

  =         for adjacent_layers in layers.windows(2) {
  =             let input_size = adjacent_layers[0].neurons;
  =             let output_size = adjacent_layers[1].neurons;

                /* ... */
            }

            /* ... */
        }
    }
  -->
</listing>

<note>
  <p>
    <ref>
      https://doc.rust-lang.org/book/ch18-03-pattern-syntax.html#destructuring-to-break-apart-values
    </ref>

    If you know about <a ref>destructuring</a>, you might've thought of
    rewriting this loop even further:
  </p>

  <listing lang="rust">
    <!--
      for [fst, snd] in layers.windows(2) {
          built_layers.push(Layer::random(fst.neurons, snd.neurons));
      }
    -->
  </listing>

  <p>
    ... but, regrettably, computer says no:
  </p>

  <listing lang="text">
    <!--
      error[E0005]: refutable pattern in `for` loop binding: `&[]`,
                    `&[_]` and `&[_, _, _, ..]` not covered
       -\-> src/lib.rs
        |
        |     for [fst, snd] in layers.windows(2) {
        |         ^^^^^^^^^^ patterns `&[]`, `&[_]` and `&[_, _, _, ..]`
        |                    not covered
        |
        = note: the matched value is of type `&[LayerTopology]`
    -->
  </listing>

  <p>
    Compiler doesn't understand that <code>.windows(2)</code> returns arrays of
    exactly two elements - for all it knows, <code>.windows(2)</code> might
    return arrays of random sizes that don't necessarily match our pattern.
  </p>

  <p>
    <i>
      (by the way, that's what <b>refutable pattern</b> means: it's a pattern
      that doesn't match all the possible cases - the antonym is <b>irrefutable
      pattern</b> and only those are allowed in places like those.)
    </i>
  </p>

  <p>
    Nightly Rust, having parts of <b>const generics</b> stabilized, offers a
    solution - <code>.array_windows()</code>:
  </p>

  <listing lang="rust">
    <!--
      #![feature(array_windows)]
      
      for [fst, snd] in layers.array_windows() {
          built_layers.push(Layer::random(fst.neurons, snd.neurons));
      }
    -->
  </listing>

  <p>
    ... but, for simplicity, we'll stay away from const generics and continue
    with the stable function.
  </p>
</note>

<p>
  In this case, switching to iterators is a no-brainer for me:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
        pub fn random(layers: Vec<LayerTopology>) -> Self {
  =         let layers = layers
  =             .windows(2)
  =             .map(|layers| Layer::random(layers[0].neurons, layers[1].neurons))
  =             .collect();
  =
  =         Self { layers }
        }
    }
  -->
</listing>

<p>
  And one final touch - when it doesn't make the code awkward, it's a good
  practice to accept <b>borrowed</b> values instead of owned:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Network {
  =     pub fn random(layers: &[LayerTopology]) -> Self {
            /* ... */
        }
    }
  -->
</listing>

<p>
  More often than not, accepting borrowed values doesn't change much inside the
  function, but it makes it more versatile - i.e. with a borrowed array one can
  now do:
</p>

<listing lang="rust">
  <!--
    let network = Network::random(&[
        LayerTopology { neurons: 8 },
        LayerTopology { neurons: 15 },
        LayerTopology { neurons: 2 },
    ]);
  -->
</listing>

<p>
  ... and:
</p>

<listing lang="rust">
  <!--
    let layers = vec![
        LayerTopology { neurons: 8 },
        LayerTopology { neurons: 15 },
        LayerTopology { neurons: 2 },
    ];
    
    let network_a = Network::random(&layers);
    let network_b = Network::random(&layers);
    //                              ^ no need to .clone()
  -->
</listing>

<p>
  What's next, what's next...​ <i>checks notes</i>...​ ah,
  <code>Layer::random()</code>!
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Layer {
  =     fn random(input_size: usize, output_size: usize) -> Self {
  =         let mut neurons = Vec::new();
  =
  =         for _ in 0..output_size {
  =             neurons.push(Neuron::random(input_size));
  =         }
  =
  =         Self { neurons }
  =     }

        /* ... */
    }
  -->
</listing>

<p>
  ... or:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Layer {
        fn random(input_size: usize, output_size: usize) -> Self {
  =         let neurons = (0..output_size)
  =             .map(|_| Neuron::random(input_size))
  =             .collect();

            Self { neurons }
        }
    }
  -->
</listing>

<note>
  <p>
    <ref>
      https://www.reddit.com/r/rustjerk/comments/8udbth/a_new_war_begins_choose_your_side/
    </ref>

    <code>|_|</code>, also known as <a ref>toilet closure</a>, is a function
    which accepts an argument it doesn't care about.
  </p>

  <p>
    We might've written as well:
  </p>

  <listing lang="rust">
    <!--
      .map(|output_neuron_id| Neuron::random(input))
    -->
  </listing>

  <p>
    ... but since we don't have to read this
    <code>output_neuron_id</code> anywhere, it's more idiomatic to name the
    argument <code>_</code> (or at least <code>_output_neuron_id</code>), to
    annotate the fact that it's not being used.
  </p>

  <p>
    <ref>
      https://doc.rust-lang.org/reference/patterns.html#destructuring
    </ref>

    Also, the <code>_</code> itself is called a <a ref>placeholder</a> and it
    can be used in a few different contexts:
  </p>

  <listing lang="rust">
    <!--
      // As a binding:
      fn ignore_some_arguments(_: usize, b: usize, _: usize) {
          //                   ^                   ^
      }
      
      // ... but not as a name:
      fn _() {
      // ^ error: expected identifier, found reserved identifier `_`
      }
      
      // As a type:
      fn load_files(paths: &[&Path]) -> Vec<String> {
          paths
              .iter()
              .map(std::fs::read_to_string)
              .collect::<Result<_, _>>()
          //                    ^  ^
              .unwrap()
      }
      
      // ... but only inside expressions:
      fn what_am_i(foo: _) {
          //            ^ error: the type placeholder `_` is not allowed
          //              within types on item signatures
      }
    -->
  </listing>
</note>

<p>
  Finally, the last piece of our chain - <code>Neuron::random()</code>:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    impl Neuron {
  =     fn random(input_size: usize) -> Self {
  =         let bias = todo!();
  =
  =         let weights = (0..input_size)
  =             .map(|_| todo!())
  =             .collect();
  =
  =         Self { bias, weights }
  =     }

        /* ... */
    }
  -->
</listing>

<p>
  Contrary to C++ or Python, Rust's standard library doesn't provide any
  pseudorandom number generator - do you know what it means?
</p>

<p class="text-center text-large text-rainbow">
  it's crates.io time!
</p>

<p>
  Which crate should we choose? Well, let's see:
</p>

<figure>
  <video src="{{ assets }}/rand.webm" />
</figure>

<p>
  <ref>
    https://rust-lang-nursery.github.io/rust-cookbook/algorithms/randomness.html
  </ref>

  When it comes to PRNGs,
  <a href="https://crates.io/crates/rand"><code>rand</code></a> is the
  <b>de facto standard</b>, <a ref>extremely versatile</a> crate which allows to
  generate not only pseudo-random numbers, but also other types such as strings.
</p>

<p>
  In order to fetch <code>rand</code>, we have to add it to our
  <code>Cargo.toml</code>:
</p>

<listing-title>
  libs/neural-network/Cargo.toml
</listing-title>

<listing lang="toml">
  <!--
    # ...
    
    [dependencies]
  = rand = "0.8"
  -->
</listing>

<p>
  ... and then:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
  = use rand::Rng;

    /* ... */

    impl Neuron {
        fn random(input_size: usize) -> Self {
  =         let mut rng = rand::thread_rng();
  =         let bias = rng.gen_range(-1.0..=1.0);

            let weights = (0..input_size)
  =             .map(|_| rng.gen_range(-1.0..=1.0))
                .collect();

            Self { bias, weights }
        }
    }
  -->
</listing>

<note>
  <p>
    <code>0..3</code> is a <b>half-open interval</b> that matches
    <code>0</code>, <code>1</code> and <code>2</code>.
  </p>

  <p>
    <code>0..=3</code> is a <b>closed interval</b> that matches <code>3</code>,
    too.
  </p>
</note>

<p>
  Neat.
</p>

<p>
  Certainly, <code>rng.gen_range(-1.0..=1.0)</code> predicts Dogecoin prices
  quite accurately - but is there a way we could ensure our <i>entire</i>
  network works as intended?
</p>

<h2 id="testing">
  Testing
</h2>

<p>
  A <a href="https://en.wikipedia.org/wiki/Pure_function">pure function</a> is a
  function whose given the same arguments, always returns the same value - for
  instance, this is a pure function:
</p>

<listing lang="rust">
  <!--
    pub fn add(x: usize, y: usize) -> usize {
        x + y
    }
  -->
</listing>

<p>
  ... while this one is not:
</p>

<listing lang="rust">
  <!--
    pub fn read(path: impl AsRef<Path>) -> String {
        std::fs::read_to_string(path).unwrap()
    }
  -->
</listing>

<p class="text-attached">
  (<code>add(1, 2)</code> will always return <code>3</code>, while
  <code>read("file.txt")</code> will return different strings depending on what
  the file happens to contain at the moment.)
</p>

<p>
  Pure functions are nice, because they can be tested in isolation:
</p>

<listing lang="rust">
  <!--
    // This test always succeeds
    // (i.e it is *deterministic*)
    #[test]
    fn test_add() {
        assert_eq!(add(1, 2), 3);
    }
    
    // This test might succeed or it might fail, impossible to anticipate
    // (i.e. it is *indeterministic*)
    #[test]
    fn test_read() {
        assert_eq!(
            std::fs::read_to_string("serials-to-watch.txt"),
            "killing eve",
        );
    }
  -->
</listing>

<p>
  Unfortunately, the way we generate numbers inside
  <code>Neuron::random()</code> makes it <b>impure</b>, which can be easily
  proven with:
</p>

<listing lang="rust">
  <!--
    #[test]
    fn random_is_pure() {
        let neuron_a = Neuron::random(4);
        let neuron_b = Neuron::random(4);
    
        // If `Neuron::random()` was pure, then both neurons would always have
        // to be the same:
        assert_eq!(neuron_a, neuron_b);
    }
  -->
</listing>

<p>
  Testing unpure functions is hard, because there's not much we can assert
  <b>reliably</b>:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    /* ... */

  = #[cfg(test)]
  = mod tests {
  =     use super::*;
  =
  =     #[test]
  =     fn random() {
  =         let neuron = Neuron::random(4);
  =
  =         assert!(/* what? */);
  =     }
  = }
  -->
</listing>

<p>
  We might try:
</p>

<listing lang="rust">
  <!--
    #[test]
    fn test() {
        let neuron = Neuron::random(4);
    
        assert_eq!(neuron.weights.len(), 4);
    }
  -->
</listing>

<p>
  ... but that's a useless test, it doesn't actually prove anything.
</p>

<p>
  On the other hand, making <code>Neuron::random()</code> a pure function
  seems...​ preposterous? What's the point of randomizing, if the outcome would
  always remain the same?
</p>

<p>
  The way I usually reconcile both worlds is by looking at the source of
  impurity - in this case, it is:
</p>

<listing lang="rust">
  <!--
    impl Neuron {
        fn random(input_size: usize) -> Self {
            let mut rng = rand::thread_rng(); // whoopsie

            /* ... */
        }
    }
  -->
</listing>

<p>
  If instead of invoking <code>thread_rng()</code>, we accepted a parameter with
  the randomizer:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
  = use rand::{Rng, RngCore};

    /* ... */

    impl Network {
  =     pub fn random(rng: &mut dyn RngCore, layers: &[LayerTopology]) -> Self {
            let layers = layers
                .windows(2)
  =             .map(|layers| Layer::random(rng, layers[0].neurons, layers[1].neurons))
                .collect();

            /* ... */
        }

        /* ... */
    }

    /* ... */

    impl Layer {
  =     fn random(rng: &mut dyn RngCore, input_size: usize, output_size: usize) -> Self {
            let neurons = (0..output_size)
  =             .map(|_| Neuron::random(rng, input_size))
                .collect();

            /* ... */
        }

        /* ... */
    }

    /* ... */

    impl Neuron {
  =     fn random(rng: &mut dyn RngCore, input_size: usize) -> Self {
            /* ... */
        }

        /* ... */
    }
  -->
</listing>

<p>
  ... then we could use a fake, <b>predictable</b> PRNG in our tests, while
  users would simply pass an actual PRNG of their choosing.
</p>

<note>
  <p>
    You can use a similar pattern to test your application's output - if instead
    of:
  </p>

  <listing lang="rust">
    <!--
      fn do_something() {
          println!("Doing something...");
          println!("... done!");
      }
    -->
  </listing>

  <p>
    ... you did:
  </p>

  <listing lang="rust">
    <!--
      fn do_something(stdout: &mut dyn Write) {
          writeln!(stdout, "Doing something...").unwrap();
          writeln!(stdout, "... done!").unwrap();
      }
    -->
  </listing>

  <p>
    ... then you'd be able to test the output quite easily:
  </p>

  <listing lang="rust">
    <!--
      #[test]
      fn ensure_something_happens() {
          let mut stdout = String::new();
          do_something(&mut stdout);
      
          assert_eq!(stdout, "Doing something...\n... done!\n");
      }
    -->
  </listing>

  <p>
    <ref>
      https://github.com/Patryk27/lxd-snapper/blob/9b096962122988abb3677a69ced244ea7cec2fa2/src/cmds/backup.rs#L159
    </ref>

    I've done this <a ref>in the past</a> and it's proven to be very convenient.
  </p>

  <p>
    <ref>
      https://en.wikipedia.org/wiki/Referential_transparency
    </ref>

    Due diligence: both <code>do_something()</code> and <code>random()</code>
    technically are <i>not</i> pure functions as they all lack a property called
    <a ref>referential transparency</a> - although, if one's insistent, there's
    always:
  </p>

  <listing lang="rust">
    <!--
      fn do_something<W: Write>(stdout: W) -> W {
          /* ... */
      }
    -->
  </listing>
</note>

<p>
  Because the <code>rand</code> crate doesn't provide a predictable or seedable
  PRNG, we have to make use of another crate - I like <code>rand_chacha</code>
  (easy to remember, you've probably already memorized it):
</p>

<listing-title>
  libs/neural-network/Cargo.toml
</listing-title>

<listing lang="toml">
  <!--
    # ...

    [dependencies]
    rand = "0.8"

  = [dev-dependencies]
  = rand_chacha = "0.3"
  -->
</listing>

<p>
  ... which allows us to do:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[cfg(test)]
    mod tests {
        use super::*;
  =     use rand::SeedableRng;
  =     use rand_chacha::ChaCha8Rng;

        #[test]
        fn random() {
  =         // Because we always use the same seed, our `rng` in here will
  =         // always return the same set of values
  =         let mut rng = ChaCha8Rng::from_seed(Default::default());
  =         let neuron = Neuron::random(&mut rng, 4);
  =
  =         assert_eq!(neuron.bias, /* ... */);
  =         assert_eq!(neuron.weights, &[/* ... */]);
        }
    }
  -->
</listing>

<p>
  We don't know which numbers will be returned just yet, but finding out is
  easy - we'll just start with zeros and then copy-paste numbers from the test's
  output:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[test]
    fn random() {
        /* ... */
    
  =     assert_eq!(neuron.bias, 0.0);
  =     assert_eq!(neuron.weights, &[0.0, 0.0, 0.0, 0.0]);
    }
  -->
</listing>

<p>
  First <code>cargo test</code> gives us:
</p>

<listing lang="text">
  <!--
    thread '...' panicked at 'assertion failed: `(left == right)`
      left: `-0.6255188`,
     right: `0.0`
  -->
</listing>

<p>
  ... so:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[test]
    fn random() {
        /* ... */
    
  =     assert_eq!(neuron.bias, -0.6255188);
    
        /* ... */
    }
  -->
</listing>

<p>
  Another <code>cargo test</code>:
</p>

<listing lang="text">
  <!--
    thread '...' panicked at 'assertion failed: `(left == right)`
      left: `[0.67383957, 0.8181262, 0.26284897, 0.5238807]`,
     right: `[0.0, 0.0, 0.0, 0.0]`', src/lib.rs:29:5
  -->
</listing>

<p>
  ... and we end up with:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[test]
    fn random() {
        /* ... */

  =     assert_eq!(
  =         neuron.weights,
  =         &[0.67383957, 0.8181262, 0.26284897, 0.5238807]
  =     );
    }
  -->
</listing>

<p>
  Notice the numbers are <i>different</i> and that's alright - they are allowed
  to be different as long as each <code>cargo test</code> consistently works on
  the same set of numbers (and it does, because we used a PRNG with a constant
  seed).
</p>

<p>
  Before moving on, there's one more topic we have to cover here:
  <b>floating-point inaccuracies</b>.
</p>

<p>
  The type we're using, <code>f32</code>, models a 32-bit floating-point number
  that can represent values between <code>~1.2*10^-38</code> and
  <code>~3.4*10^38</code> - alas, it cannot represent all of those numbers, just
  some.
</p>

<p>
  For instance, with <code>f32</code> you cannot encode exactly
  <code>0.15</code> - it'll always be off by a bit:
</p>

<listing lang="rust">
  <!--
    fn main() {
        println!("{:.10}", 0.15f32);
        // prints: 0.1500000060
    }
  -->
</listing>

<p>
  ... same with, say, <code>0.45</code>:
</p>

<listing lang="rust">
  <!--
    fn main() {
       println!("{:.10}", 0.45f32);
       // prints: 0.4499999881
    }
  -->
</listing>

<p>
  Usually it doesn't matter, because floating-point numbers were never made to
  be exact (only fast) - but when it does come up, it hits one like a brick
  falling from the sky:
</p>

<listing lang="rust">
  <!--
    #[test]
    fn test() {
        assert_eq!(0.45f32, 0.15 + 0.15 + 0.15);
    }
  -->
</listing>

<listing lang="text">
  <!--
    thread 'test' panicked at 'assertion failed: `(left == right)`
      left: `0.45`,
     right: `0.45000002`'
  -->
</listing>

<p>
  To avoid reinventing the wheel, I'll just drop this link:
  <a href="https://floating-point-gui.de">
    What Every Programmer Should Know About Floating-Point Arithmetic
  </a>
  - if you haven't read about floating-point numbers yet, I encourage you to
  give it a shot!
</p>

<p>
  So, if we shouldn't compare numbers exactly, what can we do? Compare them
  <b>approximately</b>!
</p>

<listing lang="rust">
  <!--
    #[test]
    fn test() {
        let actual: f32 = 0.1 + 0.2;
        let expected = 0.3;
    
        assert!((actual - expected).abs() < f32::EPSILON);
    }
  -->
</listing>

<p>
  <ref>
    https://en.wikipedia.org/wiki/IEEE_754
  </ref>

  This is the standard way to compare floats across all programming languages
  that implement <a ref>IEEE 754</a> (so, like, all programming languages) -
  instead of fishing for an exact result, you compare both numbers with a
  <b>margin of error</b> (also called <b>tolerance</b>).
</p>

<p>
  Because comparing numbers this way is awkward, it's more cushy to either do it
  via a macro:
</p>

<listing lang="rust">
  <!--
    macro_rules! assert_almost_eq {
        ($left:expr, $right:expr) => {
            let left: f32 = $left;
            let right: f32 = $right;
    
            assert!((left - right).abs() < f32::EPSILON);
        }
    }
    
    #[test]
    fn test() {
        assert_almost_eq!(0.45f32, 0.15 + 0.15 + 0.15);
    }
  -->
</listing>

<p>
  ... or - which is the best approach - using a crate such as
  <a href="https://docs.rs/approx/0.4.0/approx/">approx</a>:
</p>

<listing lang="rust">
  <!--
    #[test]
    fn test() {
        approx::assert_relative_eq!(0.45f32, 0.15 + 0.15 + 0.15);
    }
  -->
</listing>

<p>
  I personally like <code>approx</code>, so let's add it to our neural network's
  <code>Cargo.toml</code>:
</p>

<listing-title>
  libs/neural-network/Cargo.toml
</listing-title>

<listing lang="toml">
  <!--
    # ...
    
    [dev-dependencies]
  = approx = "0.4"
    rand_chacha = "0.3"
  -->
</listing>

<p>
  ... and then adjust the tests:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    use super::*;
  = use approx::assert_relative_eq;
    use rand::SeedableRng;
    use rand_chacha::ChaCha8Rng;

    #[test]
    fn random() {
        let mut rng = ChaCha8Rng::from_seed(Default::default());
        let neuron = Neuron::random(&mut rng, 4);
    
  =     assert_relative_eq!(neuron.bias, -0.6255188);

  =     assert_relative_eq!(
  =         neuron.weights.as_slice(),
  =         [0.67383957, 0.8181262, 0.26284897, 0.5238807].as_ref()
  =     );
    }
  -->
</listing>

<p>
  This covers half of neuron's functions - thankfully, knowing what we know now,
  writing a test for <code>Neuron::propagate()</code> will go easy:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[cfg(test)]
    mod tests {
        /* ... */

        #[test]
        fn random() {
            /* ... */
        }
  =
  =     #[test]
  =     fn propagate() {
  =         todo!()
  =     }
    }
  -->
</listing>

<note>
  <p>
    You might've heard that it's useful to name tests based on their
    <b>preconditions</b> and <b>expectations</b>.
  </p>

  <p>
    Usually that's true - if we were writing a shop, it could be useful to
    structure its tests like so:
  </p>

  <listing lang="rust">
    <!--
      #[cfg(test)]
      mod tests {
          use super::*;
      
          mod cart {
              use super::*;
      
              mod when_user_adds_a_flower_to_their_cart {
                  use super::*;
      
                  #[test]
                  fn user_can_see_this_flower_in_their_cart() {
                      /* ... */
                  }
      
                  #[test]
                  fn user_can_remove_this_flower_from_their_cart() {
                      /* ... */
                  }
      
                  mod and_submits_order {
                      /* ... */
                  }
      
                  mod and_abandons_cart {
                      /* ... */
                  }
              }
          }
      }
    -->
  </listing>

  <p>
    The sitch is that our <code>Neuron</code> isn't typical "business code" and
    lots of "business code patterns" don't quite work with mathematical code. If
    we had some <b>edge cases</b> to consider, say:
  </p>

  <listing lang="rust">
    <!--
      fn propagate(/* ... */) {
          if /* ... */ {
              do_foo()
          } else {
              do_bar()
          }
      }
    -->
  </listing>

  <p>
    ... then it'd make sense to create two separate tests:
  </p>

  <listing lang="rust">
    <!--
      #[cfg(test)]
      mod tests {
          use super::*;
      
          mod propagate {
              use super::*;
      
              mod given_neuron_with_foo {
                  use super::*;
      
                  #[test]
                  fn fooifies_it() {
                      /* ... */
                  }
              }
      
              mod given_neuron_thats_bar {
                  use super::*;
      
                  #[test]
                  fn bars_it() {
                      /* ... */
                  }
              }
          }
      }
    -->
  </listing>

  <p>
    ... but having the code we have - we're better off with simple
    <code>fn random()</code> and <code>fn propagate()</code>.
  </p>
</note>

<p>
  How can we ensure <code>propagate()</code> works correctly? By computing the
  expected response manually:
</p>

<listing-title>
  libs/neural-network/src/lib.rs
</listing-title>

<listing lang="rust">
  <!--
    #[test]
    fn propagate() {
  =     let neuron = Neuron {
  =         bias: 0.5,
  =         weights: vec![-0.3, 0.8],
  =     };
  =
  =     // Ensures `.max()` (our ReLU) works:
  =     assert_relative_eq!(
  =         neuron.propagate(&[-10.0, -10.0]),
  =         0.0,
  =     );
  =
  =     // `0.5` and `1.0` chosen by a fair dice roll:
  =     assert_relative_eq!(
  =         neuron.propagate(&[0.5, 1.0]),
  =         (-0.3 * 0.5) + (0.8 * 1.0) + 0.5,
  =     );
  =
  =     // We could've written `1.15` right away, but showing the entire
  =     // formula makes our intentions clearer
    }
  -->
</listing>

<p>
  From this point, implementing tests for <code>Layer</code> and
  <code>Network</code> gets pretty straightforward and thus has been left as an
  exercise for the reader :-)
</p>

<h2 id="closing-thoughts">
  Closing thoughts
</h2>

<h3>
  What have we created, exactly?
</h3>

<p>
  It might seem that what we've implemented has nothing to do with learning or
  simulating:
</p>

<ul>
  <li>
    <p>
      what about the eyes?
    </p>
  </li>
  <li>
    <p>
      where's the code responsible for movement?
    </p>
  </li>
  <li>
    <p>
      how did you create that greenish, Fallout-style terminal?
    </p>
  </li>
</ul>

<p>
  ... but that's only because the neural network itself, while being a
  relatively complex piece of our codebase, doesn't do much on its own - thou
  shall not worry, though, for in the end all the pieces shall fit together.
</p>

<p>
  <ref>
    https://github.com/Patryk27/shorelark/tree/main/libs/neural-network
  </ref>

  In the meantime, feel free to checkout <a ref>the source code</a>.
</p>

<h3>
  Is our design inflated?
</h3>

<p>
  When you search for <code>python neural network from scratch</code>, you'll
  find lots of articles which encapsulate FFNNs in a few lines of Python code -
  compared to them, our design seems inflated, why is that so?
</p>

<p>
  <ref id="nalgebra">
    https://nalgebra.org/
  </ref>

  <ref id="nn-crates">
    https://www.arewelearningyet.com/neural-networks/
  </ref>

  It's because we could learn more this way - we <i>could've</i> coded our
  network in 1/10th of its current size by using <a ref="nalgebra">nalgebra</a>,
  we <i>could've</i> used one of the <a ref="nn-crates">already-existing
  crates</a>, but it's not the destination that matters, it's the journey.
</p>

<h3>
  What’s next?
</h3>

<p>
  At the moment we've got a bare-bones FFNN at hand - in the next article we'll
  be implementing the genetic algoritm and we'll be connecting it to our neural
  network. The last post will be all about WebAssembly-ing our crates together
  to end up with our opus magnum: flying birds.
</p>
